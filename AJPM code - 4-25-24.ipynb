{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV, GroupShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from external CSV file. E.g., \n",
    "\n",
    "df = pd.read_csv(...)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9342900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the input of predictor variables. Dummy names shown below instead of the real variable names.\n",
    "# y is the outcome variable\n",
    "# groups is the array indicating the hierarchical structure (e.g., state)\n",
    "\n",
    "X = df[['var1','var2','etc']]  \n",
    "y = df[['outcome']]\n",
    "groups = df[['STATE']]\n",
    "\n",
    "# Convert groups to numeric representation using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "groups_numeric = le.fit_transform(groups)\n",
    "\n",
    "# Create a GroupShuffleSplit object to perform the train-test split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=16)\n",
    "\n",
    "# Perform the train-test split while maintaining the hierarchical structure and blocked data\n",
    "train_index, test_index = next(gss.split(X, y, groups_numeric))\n",
    "\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "else:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "groups_train, groups_test = groups_numeric[train_index], groups_numeric[test_index]\n",
    "\n",
    "# Create a GroupKFold object to handle hierarchical data and blocked data\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning. E.g.,\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.05, 0.1, 1, 10, 100], 'l1_ratio': [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99, 1.0]}\n",
    "\n",
    "# Create an ElasticNet regression model\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Perform grid search with nested cross-validation for hierarchical data\n",
    "grid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid, cv=gkf, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters: \", best_params)\n",
    "\n",
    "# Evaluate the model using nested cross-validation\n",
    "cv_scores = -grid_search.cv_results_['mean_test_score']\n",
    "mse_scores = np.sqrt(cv_scores)\n",
    "\n",
    "print(\"Nested cross-validation MSE scores: \", mse_scores)\n",
    "print(\"Mean nested cross-validation MSE: \", np.mean(mse_scores))\n",
    "\n",
    "# Evaluate the best model on the unseen outter loop test set\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE for the test set\n",
    "test_mse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "print(\"Test set MSE: \", test_mse)\n",
    "\n",
    "# Calculate RMSE for the test set\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "print(\"Test set RMSE: \", test_rmse)\n",
    "\n",
    "# Get the final feature importances from the best model\n",
    "importances = best_model.coef_\n",
    "\n",
    "# Create a dataframe to store the feature importances\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': np.abs(importances)})\n",
    "else:\n",
    "    feature_importances = pd.DataFrame({'Feature': range(X.shape[1]), 'Importance': np.abs(importances)})\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 important predictors and their absolute values\n",
    "print(\"Top 10 Important Predictors:\")\n",
    "print(feature_importances.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-regularized modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9909356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the input of predictor variables. Dummy names shown below instead of the real variable names.\n",
    "# y is the outcome variable\n",
    "# groups is the array indicating the hierarchical structure (e.g., state)\n",
    "\n",
    "X = df[['var1','var2','etc']]  \n",
    "y = df[['outcome']]\n",
    "groups = df[['STATE']]\n",
    "\n",
    "le = LabelEncoder()\n",
    "groups_numeric = le.fit_transform(groups)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=16)\n",
    "\n",
    "train_index, test_index = next(gss.split(X, y, groups_numeric))\n",
    "\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "else:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "groups_train, groups_test = groups_numeric[train_index], groups_numeric[test_index]\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in gkf.split(X_train, y_train, groups_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    linear_model.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = linear_model.predict(X_test_fold)\n",
    "    mse_fold = mean_squared_error(y_test_fold, y_pred_fold)\n",
    "    cv_scores.append(mse_fold)\n",
    "\n",
    "print(\"Cross-validation MSE scores: \", cv_scores)\n",
    "print(\"Mean cross-validation MSE: \", np.mean(cv_scores))\n",
    "\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = linear_model.predict(X_train)\n",
    "y_pred_test = linear_model.predict(X_test)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"Test set MSE: \", test_mse)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "print(\"Test set RMSE: \", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2288e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy regressor modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the input of predictor variables. Dummy names shown below instead of the real variable names.\n",
    "# y is the outcome variable\n",
    "# groups is the array indicating the hierarchical structure (e.g., state)\n",
    "\n",
    "X = df[['var1','var2','etc']]  \n",
    "y = df[['outcome']]\n",
    "groups = df[['STATE']]\n",
    "\n",
    "le = LabelEncoder()\n",
    "groups_numeric = le.fit_transform(groups)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=16)\n",
    "\n",
    "train_index, test_index = next(gss.split(X, y, groups_numeric))\n",
    "\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "else:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "groups_train, groups_test = groups_numeric[train_index], groups_numeric[test_index]\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "dummy_model = DummyRegressor(strategy='mean')\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in gkf.split(X_train, y_train, groups_train):\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    dummy_model.fit(np.zeros((len(y_train_fold), 1)), y_train_fold)\n",
    "    y_pred_fold = dummy_model.predict(np.zeros((len(y_test_fold), 1)))\n",
    "    mse_fold = mean_squared_error(y_test_fold, y_pred_fold)\n",
    "    cv_scores.append(mse_fold)\n",
    "\n",
    "print(\"Cross-validation MSE scores: \", cv_scores)\n",
    "print(\"Mean cross-validation MSE: \", np.mean(cv_scores))\n",
    "\n",
    "dummy_model.fit(np.zeros((len(y_train), 1)), y_train)\n",
    "\n",
    "y_pred_train = dummy_model.predict(np.zeros((len(y_train), 1)))\n",
    "y_pred_test = dummy_model.predict(np.zeros((len(y_test), 1)))\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"Test set MSE: \", test_mse)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "print(\"Test set RMSE: \", test_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
